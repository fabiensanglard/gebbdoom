\section{The Intel 486}

\begin{wrapfigure}[5]{r}{0.25\textwidth}
\centering
\includegraphics[width=.25\textwidth]{drawings/intel_logo.pdf}
\end{wrapfigure}

Announced in 1989, the 80486 was a performance evolution that addressed all the bottlenecks of the 80386. However, its price tag of \$950 (\$1,920 in 2018) kept it away from most consumers. By 1993 it was finally becoming affordable (\$500) and would become \doom{}'s recommended CPU.\\
\par
The design had changed significantly compared to its predecessor. The pipeline was gifted with two extra stages, extending its depth to five elements. The FPU\footnote{Floating Point Unit.}, which used to be optional and somewhere on the motherboard was brought on-die. Most importantly, manufacturing improvements\footnote{The 1.0$\mu$ process (vs the i386's 1.5$\mu$) and a die size increase allowed five times more transistors for a total of 1.2 million (the i386 featured 275,000).  It was the first x86 chip to include more than one million transistors.} allowed the 486 a more elaborate design that finally featured an integrated L1 cache -- something Intel had attempted with the 386 without success.\\
\par
\fq{The 386 actually had a small cache that eventually got exited because it didn't have enough performance for the size of the cache that we could put on board the chip. The problem was that if you made the chip bigger, it literally wouldn't fit inside the lithography machine's field of view, to flash on the chip.}{Gene Hill - Intel 386 Microprocessor Design and Development}\\
\par
{
\setlength{\belowcaptionskip}{-10pt}
\drawing{486_arch}{Intel 486 architecture.}
}
\pagebreak
Like with the 386, Intel marketed its new CPU in two flavors. The DX version was the pure technology, while the SX version had an unavailable FPU. A decades-old diehard myth is that the DX/SX distinction was a marketing stunt from Intel to sell chips coming out of the factory with malfunctioning parts due to manufacturing problems. It was in fact an intentional commercial operation\footnote{Source: "Lies, Damn Lies, and Wikipedia" by Michal Necasek; The timeline did not make sense since "The 486DX started shipping in volume in late 1989. The 486SX was only introduced in mid-1991. In the first 18 months or so when yield problems would have been the worst, there was no SX.".} to provide a discounted (50\%) price and an opportunity to sell i487 FPU co-processors.\footnote{Amusingly, the i487 FPU upgrade was a full-blown 486DX that disabled the 486SX completely!}.\\
\par
If in retrospect the 486 was Intel's 1994 champion and an unquestionable powerhouse (both in terms of performance and sales\footnote{As of late 2015, the 486 was still manufactured and used inside network routers.}), it had to sustain a period of uncertainty. Just as the 386 had to face its brother (the i960), the i486 also had to face a challenger from the same company. The competing sibling was named the "Intel 860".\\
\par
\fq{

\begin{wrapfigure}[11]{r}{0.55\textwidth}
\centering
\scaledimage{0.55}{i860.png}
\end{wrapfigure}

...We now had two very powerful chips that we were introducing at just about the same time: the 486, largely based on CISC technology and compatible with all the PC software, and the i860, based on RISC technology, which was very fast but compatible with nothing. We didn't know what to do. So we introduced both, figuring we'd let the marketplace decide. However, things were not that simple. Supporting a microprocessor architecture with all the necessary computer-related products --- software, sales, and technical support --- takes enormous resources. Even a company like Intel had to strain to do an adequate job with just one architecture. And now we had two different and competing efforts, each demanding more and more internal resources. Development projects have a tendency to want to grow like the proverbial mustard seed. The fight for resources and for marketing attention (for example, when meeting with the customer, which processor should we highlight) led to internal debates that were fierce enough to tear apart our microprocessor organization. Meanwhile, our equivocation caused our customers to wonder what Intel really stood for, the 486 or i860?}{Andy Grove, "Only the paranoid survive"}





On paper, the i860 was impressive and a serious opponent. Relying on a heavily pipelined super-scalar architecture crushing VLIWs\footnote{Very Long Instruction Word.}, it had three units (X, Y, and Z) allowing parallel processing and when used efficiently could outperform the Intel 486.\\
\par
But whereas later CPUs such as the Pentium chose to hide the chip's complexity by automatically executing instructions in parallel when possible, the i860's architecture mandated direct manipulation of its parallel pipelines. The chip did nothing behind the scenes and relied on compiler writers to sequence instructions appropriately.\\
\par
Unfortunately, compiler technology was not there yet. Without Intel's full backing to generate the precious tool, none of the compilers available came even remotely close to generating instructions able to exploit its super-scalar capability. The i860 was never able to reach its full potential. If only Intel had been willing to build the tools it desperately needed, the history of the i860 could have been different.\\
\par
\par
\cscaledimage{0.85}{i486DX.png}{The Intel 80486 package.}
\par
Figure \ref{i486DX.png} shows the Intel 486 die featuring 1,180,235 transistors inside its package. Around this time period, Intel started to stamp its CPU with a trademarked logo in an attempt to distance itself from increasingly aggressive AMD and Cyrix clones.\\
\par
\trivia{The i860 played a part in \doom{} anyway since it was used in the NeXTDimension's video processing boards.}

\par
\subsection{Pipeline improvements}
Charting the 486's MIPS performance against the previous generation makes the performance boost appear vividly. Thanks to a better manufacturing process, top of the line 486s were able to run at 50MHz\footnote{To reach this frequency, 486 DX 50MHz were manufactured at 1.0$\mu$.}, but frequency increase was not the main source of the improvement.\\
\par
 Looking closely at the chart, one will notice that even at equal frequencies, a 486 offered more than twice the processing power of a 386.\\

\par
\begin{figure}[H]
\centering
  \begin{tikzpicture}[font=\small]
    \begin{axis}[
      width=1.0\textwidth,
      height=0.8\textwidth,
      ybar,
      bar width=20pt,
      ylabel={MIPS},
      ymin=0,
      ytick=\empty,
      xtick=data,
      axis x line=bottom,
      axis y line=left,
      enlarge x limits=0.11,
      symbolic x coords={386 16MHz,386 25MHz,386 33MHz,486 25MHz,486 33MHz,486 50MHz},
      xticklabel style={anchor=base,yshift=-\baselineskip},
      nodes near coords={\pgfmathprintnumber\pgfplotspointmeta}
    ]
      \addplot[fill=black!20,draw=black] coordinates {
        (386 16MHz,4)
        (386 25MHz,6)
        (386 33MHz,8)
        (486 25MHz,15)
        (486 33MHz,20)
        (486 50MHz,30)
      };
    \end{axis}
   
   \end{tikzpicture}
   \caption{Comparison of Intel CPUs with MIPS\protect\footnotemark.}
 \end{figure}
\footnotetext{"Million of Instructions Per Seconds (MIPS). Source: Roy Longbottom's PC Benchmark: http://www.roylongbottom.org.uk/mips.htm.}

The way it achieves higher performance is through a higher average throughput. Its documentation describes the 386 as a three-stage pipelined processor. Figure \ref{386_doc_pipeline} shows how, under ideal conditions, it should have been able to execute one instruction per cycle. In practice the CPU behaved as shown in figure \ref{386_real_pipeline}, two times slower than suggested.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{drawings/386_instruction_pipeline.pdf}
\caption{386 pipeline in theory according to Intel documentation.}
\label{386_doc_pipeline}
\end{figure}



\par
Even if the Prefetch Unit and the Execution Unit were properly fed, the Decode unit always took a minimum of two cycles to decode an instruction\footnote{Decoding is complex since x86 uses variable-length instructions, contrary to RISC's fixed-length approach.}. Since the maximum throughput of a pipeline cannot exceed the speed of its slowest stage, the Intel 386 could process at most one instruction every two cycles.\\
\par

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{drawings/actual_386_instruction_pipeline.pdf}
\caption{386 pipeline in practice: Two cycles per instruction.}
\label{386_real_pipeline}
\end{figure}

\par
To solve this problem, Intel broke down the three stage pipeline into five (Prefetch, Decode1, Decode2, Execute, WriteBack). With all stages performing at 1 CPI\footnote{Cycle Per Instruction.}, the total throughput of the 486 was doubled (as long as the pipeline never starved).\\
\par
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{drawings/actual_486_instruction_pipeline.pdf}
\caption{486 pipeline: One cycle per instruction.}
\end{figure}
\par





\subsection{Caching }
Modifying the pipeline and making each stage run as fast as the others was one step in the right direction. But making the pipeline deeper also made it more vulnerable to starvation. Starting from an empty pipeline, the 486 had a latency of 5 cycles compared to the 386, which had a latency of 4 cycles. A frequently stalling 486 would have been slower than a 386. Halting processing due to missing data or instructions was to be avoided at all cost.\\
\par
It was a problem seemingly impossible to solve for a technical standing point. Since 1980, RAM performance had been lagging behind CPU performance. Each year, CPUs performance improved by 60\% while DRAM had only improved by 7\%, the gap increasing by 50\% per year. By 1989, DRAM access time was 10 times slower than CPU cycle time.\\
\par
\vspace{2mm}
\drawing{ram_vs_cpu}{Source: "Computer Organization and Design" by Hennessy and Patterson}
\par
Until the 486, a CPU requesting either instructions or data from DRAM always had to stall and go through its Bus Unit to talk to the motherboard memory controller. As optimized as the ISA bus protocol was, it took at the very minimum two cycles.\\
\par 
A first cycle initialized the bus request, placed the address on the address line and set the control line (Read/Write). Then, a wait cycle ran (which Intel called Wait State since while waiting on the Bus Unit, the CPU did absolutely nothing) while the device on the other side of the bus fulfilled the request.\\
\par
\drawing{cpu_chipset_bus}{386 CPU-RAM communication elements.}
\par
If a device was able to answer the bus request within the first wait state cycle, the CPU was able to resume operations having reached Zero Wait state. Otherwise, additional Wait States were inserted in order to wait for the request to be completed. From a performance perspective, these Wait States were a disaster. Not only because it took longer for the instruction to finish but also because it stalled all other instructions in the pipeline.\\
\par
\rawdrawing{cpu_wait_states}
\par
A two-cycle bus request was the fastest a CPU could achieve. In practice, DRAM access required several Wait State insertions.
To avoid this meant avoiding using the bus completely. Therefore, Intel inserted a new component between the pipeline and the bus unit called the L1 (Level 1) cache. The idea was to exploit both the spatial and temporal locality of a program.\\
\par
Temporal locality relies on the iterative nature of programs. While in a loop, a recently accessed instruction is likely to be accessed again on the next iteration. Spatial locality has to do with the way programs sequentially read or write arrays containing data. If a memory address is accessed, it is likely a neighboring address will also be accessed shortly after.\\
\par
By leveraging these two properties, a well-designed cache located between the CPU and the Bus Unit would often already contain the requested data or instruction, making a bus request unnecessary.\\
\par
\drawing{cpu_cache}{486 CPU-RAM communication elements.}



\vspace{-20pt}
\subsection{L1 Cache}
Hopefully it is now abundantly clear that the cache was the cornerstone of the entire CPU. Designing the cache to yield the highest hit rate possible and making it as fast as possible were paramount. 

\subsubsection{DRAM vs SRAM}
The first thing the cache had going for itself was the lower latency of its RAM. While the main RAM in the SIMM slots used DRAM (Dynamic RAM), the cache was made of a different type called SRAM (Static RAM), with a much faster access time. DRAM typically had an access time of 200ns while SRAM was capable of 20ns, 10x faster.\\
\par
The difference in speed comes from the design of their elementary cells.\\
\par
 A DRAM cell holds a single bit. Its simple design features one transistor and one storage capacitor which allow tight packing and high capacity. However, the capacitor loses its charge over time and each time it is accessed. Every time the cell is read, it must be written back with its value. Even if it is not accessed, it must be refreshed every 15$\mu s$.\\
\par
\scaleddrawing{1}{DRAM}{Dynamic RAM and its two elements holding one bit of data.}
\vspace{-5pt}
The slowness comes from the high maintenance cost of each cell. The DRAM also has the disadvantage of being far away. Located somewhere on the motherboard, it requires using the ISA bus which is shared with other devices.\\
\par

\vspace{2mm}
Thanks to a more elaborate design (which made it less dense but more expensive to manufacture), an SRAM cell has none of these disadvantages.\\
\par
\scaleddrawing{1}{SRAM}{Static RAM made of six elements.}
\par
Without a capacitor, an SRAM cell doesn't leak. It does not need a periodic refresh and it does not need to be written back each time it is accessed. Its two bit lines allow twice as fast voltage variation detection and faster timing.
Since it is located inside the CPU chip, accessing it doesn't require an expensive bus request and there is no contention with other devices\footnote{DRAM speed improved over the years. Fast Page Mode "cached" rows of DRAM cells with an SDRAM row buffer. udacity.com's UPCF courses are excellent if you want to learn more about this topic.}.
\par










\subsubsection{Cachelines}
Not only did the L1 cache have better hardware, it was also cleverly designed. Its small size (8 KiB) and heavy duty (unified cache for both code and data) placed a considerable stress on it, yet it managed an impressive 92\% hit rate\footnote{Source: "The i486 CPU: Executing Instructions in One Clock Cycle".} under normal operation.\\
\par
To achieve this, Intel engineers used a four-way associative design where the $2^{32}$ address space is divided into 2,097,152 pages of 2 KiB. Within each page there are 128 lines of 16 bytes called cachelines.\\
\par
\drawing{cacheline}{The 16 bytes in a cacheline.}
\par
The cache system is made of one directory and four banks (also called ways). Each way can store 128 cachelines of 16 bytes and therefore has a capacity of 2 KiB. These lines of 16 bytes are the elementary units of the cache.\\
\drawing{mem_to_way}{How a memory address is interpreted by the cache controller.}
\par
Upon receiving a 32-bit address access request, the cache controller splits it into the three fields shown in Figure \ref{mem_to_way} and performs the following steps.
\begin{enumerate}
\item Use the LINE field [4-10] to look up one of the 128 directory entries.
\item Look at the four tags in the entry. If one matches the TAG [11-31] then it means the cacheline is present in one of the four ways.
\item Check the flag F in the directory entry to make sure the cacheline is valid.
\item Use the OFFSET [0-3] field to access one of the 16 values in the cacheline.
\item Update the flag F in the directory entry to update the LRU\footnote{Least Recently Used.}  value.
\end{enumerate}
\par
A memory address' content can be in any of the four ways but always at the same LINE offset. With $2^{32} / 128 = 33,554,432$ addresses competing for four slots, the unavoidable cacheline evictions are arbitrated via an LRU policy\footnote{Eviction can happen on read but also on write if the cache is write-allocate, which all Intel 486s were (Source: "Internal Cache Architecture of X86 Processors").}.\\
\par
\drawing{cacheways}{The cache controller and its four ways (banks).}
\par
\trivia{What about increasing the number of ways or the cache size? With 8 KiB of cache, four ways grant the best trade-off\footnote{Source: "Computer Architecture: A Quantitative Approach" by Hennessy/Patterson.}. A two-ways cache yields a 14\% miss rate and a 4-ways cache yields a 10.5\% miss rate. However, going up to eight only improves the percentage to 10\%, and fully associative to 9\%.}\\
\par

\rawscaleddrawing{0.9}{set_state_caches}



\subsection{Bus Burst Transfer}
Any cache miss within the 486 pipeline triggered the eviction of a cacheline and a full 16 bytes had to be transfered from DRAM to SRAM\footnote{The prefetcher also worked with units of 16 bytes. It retrieved and stored cachelines into a prefetch queue of 32 bytes.}. Normally this would have been a very costly operation and a huge issue for the CPU. But Intel added something called "Burst Transfer" capability to make it all work together.\\
\par
The principle was simple: While waiting for data to arrive, latch the next request so the bus controller can use it right away without waiting for the CPU to initialize a bus request.\\
\par
\drawing{netburst}{"Burst Transfer" allows for 65\% faster cacheline filling.}







\subsection{Overdrive and L1 Writeback}
Intel managed to improve performance by 33\% with its line of 80486 OverDrive chips. These CPUs featured a frequency multiplier that made them run two times faster than the bus (the 33MHz model CPU ran at 66MHz)\footnote{To this day, designers still try to solve the problem of having a CPU so much faster than the bus.}.  Furthermore, the L1 cache policy became write-back (instead of write-through) which reduced bus traffic significantly.\\
\par 
\vspace{10pt}
\scaleddrawing{0.9}{486dx2_notm}{The "DX2-66" was the golden standard and absolute best to run \doom{}}%{Best CPU to run \doom at the time.}
\par
%\trivia{Want even more performance? Not only a DX2-66 ran faster, they also came with an enhanced writeback L1 cache\footnote{The standard 486 L1 cache was writethrough with post-writes.}}

\begin{figure}[H]
\centering
  \begin{tikzpicture}[font=\small]
    \begin{axis}[
      width=1.0\textwidth,
      height=0.6\textwidth,
      ybar,
      bar width=20pt,
      ylabel={MIPS},
      ymin=0,
      ytick=\empty,
      xtick=data,
      axis x line=bottom,
      axis y line=left,
      enlarge x limits=0.11,
      symbolic x coords={486 DX 25MHz,486 DX 33MHz,486 DX 50MHz,486 DX2 66MHz},
      xticklabel style={anchor=base,yshift=-\baselineskip},
      nodes near coords={\pgfmathprintnumber\pgfplotspointmeta}
    ]
      \addplot[fill=black!20,draw=black] coordinates {
        (486 DX 25MHz,15)
        (486 DX 33MHz,20)
        (486 DX 50MHz,30)
        (486 DX2 66MHz,34)
      };
    \end{axis}
   
   \end{tikzpicture}
   \caption{Comparison of CPUs with MIPS \protect\footnotemark.}
 \end{figure}
\footnotetext{Source: "Roy Longbottom's PC Benchmark Collection: http://www.roylongbottom.org.uk/mips.htm".}
\par
On the chart above, notice how a 486DX2-66MHz is faster than a 486DX-50MHz but not by the full 20\% that frequency would make us expect. This is because the DX2 bus runs at 33MHz while on the DX, both the CPU and bus run at 50MHz.




\subsection{Die}
%To close this section on the 486, I cannot resist including a magnified photography of the die. 
If you are holding a physical 9.25''x7.5'' copy of this book, the CPU packaging is 30mm square and the die is 15.5 x 9.9 mm, both represented at 1:1 scale.\\
\par
\bigskip

  \begin{figure}[!htb]

\begin{minipage}{0.48\textwidth}
\centering
\scaledrawimage{44.45mm}{486topdown.png}
%\caption{468 packaging.}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
\centering
\includegraphics[width=44.45mm]{drawings/486toscale.pdf}
%\caption{The die inside the package.}
\end{minipage}
\end{figure}

\par



\begin{figure}[H]
\centering
\scaledimage{0.9}{486_blueprint.png}
\end{figure}
\par
\begin{figure}[H]
\centering
\scaledimage{0.9}{486_layout.png}
\end{figure}





\trivia{On the previous page, the transistor layout differs between the data path, which was hand-crafted, and the control path, which was created with CAD tools built especially for the 486\footnote{Source: Coping with the Complexity of Microprocessor Design at Intel -- A CAD History.}.}\\
\par
\subsection{Programming the 486}
With the architecture in mind we can now understand how a programmer could take best advantage of the 486. The good news was that most of the performance improvement was the characterized free-lunch of the 90s. The exact same binary would run twice as fast on the new CPU.\\
\par
Apart from a few peculiarities\footnote{"Pushing the 486" by Michael Abrash.}, as long as the programmer was mindful of the cachelines and maximized time and space locality\footnote{And avoided branching. Without a branch predictor, \cw{jmp}s are ignored and usually incur a two cycle stall.}, the CPU would fly in processing integers. Floating-point operations had improved by a factor of 2 compared to the i386's FPU (i387). In fact, floating point operations had improved so much that the i487 FPU could \cw{FMUL} faster than the i386 could \cw{IMUL}.\\
\par
\begin{figure}[H]
\centering
\begin{tabularx}{\textwidth}{ X  X X  X  X}
  \toprule
  \textbf{CPU} & \textbf{FADD} & \textbf{FMUL} & \textbf{FDIV} &\textbf{FXCH} \\
  \toprule
Intel 387 & 23-34 & 29-57   & 88-91 & 18 \\
Intel 487 & 8-20  & 16   & 73 & 4 \\ \bottomrule
\end{tabularx}
\caption{FPU cycles per instruction: 387 vs 487.}

\end{figure}

\par
But the FPU performance was still a far cry compared to the ALU and its barrel shifter. This mandated \doom{} to use integer operations exclusively\footnote{The dawn of floating-point in games would begin with Intel's Pentium and Quake in 1996.}.\\

\par
 \begin{figure}[H]
\centering  
\begin{tabularx}{\textwidth}{ L{0.25} L{0.25} L{0.25} L{0.25} }
  \toprule
  \textbf{CPU} &  \textbf{ADD}  & \textbf{MUL} & \textbf{DIV}\\
  \toprule 
   i487 (FPU) & 8-20  & 16 & 73\\
   i486 (ALU) & 1  & 12-42 & 43\\
   \toprule
\end{tabularx}
\caption{Cycles per instruction: ALU vs FPU.}
\end{figure}

%  \begin{figure}[H]
% \centering  
% \begin{tabularx}{\textwidth}{ L{0.3} L{0.3} L{0.4}}
%   \toprule
%   \textbf{Operation} &  \textbf{i486 (ALU)} & \textbf{i487 (FPU)} \\
%   \toprule 
   
%    \cw{ADD} & 1 & 8-20\\
%    \cw{DIV} & 43 & 73\\
%    \cw{MUL} & 12-42 & 29-52\\
%    \toprule
% \end{tabularx}
% \caption{Cycles per instruction of ALU vs FPU.}
% \end{figure}

\par
\trivia{Difficulty in accessing information birthed myths about \doom{} and floating point units. One endless thread that occurred on \cw{alt.games.doom} in 1994 helps to appreciate the state of things. The topic, "Does a 486DX run Doom faster than an SX?" from July 1994 and its (filtered) five answers shows how difficult it was to reach the truth.}


\fq{\cw{My friend is buying a computer and doesn't see much reason to buy
a DX.  Any opinions?  (or hard facts :) ?).}}{\cw{Dave Gates@bestsd.sdsu.edu - 23 Jul 1994 05:28}}


\vspace{1mm}

\fq{\cw{DOOM runs *MUCH* faster on a 486DX/33 than on a 486SX/33.  Believe me,
I've seen it running on the 2 different machines in the same room.} }{\cw{BillyBoB 4@aol.com - 23 Jul 1994 10:45}}

\vspace{1mm}

\fq{\cw{They are *NOT* any different as far as CPU speed go.  Period.
The reason one (DX) is faster must have something to do with
probably the SX has an ISA video card, or no cache, or less
memory. Doom does NOT NOT NOT NOT use an FPU (math co-processor) so there will be no slowdown for the SX.}}{\cw{Chad Anson@daisy.cc.utexas.edu - 23 Jul 1994 11:48}}

\vspace{1mm}

\fq{\cw{We have a 486SX/25 and a 486DX/50 and the DX 50 runs faster at full screen
high detail then the SX runs at postage stamp. It is so slow as to be
almost unplayable.} }{\cw{BonesBro@aol.com - 23 Jul 1994 12:36}}

\vspace{1mm}

\fq{\cw{An SX is considerably slower than a DX for most processor-intensive
applications and games, including DOOM.}}{\cw{Neal W.Miller@@rebecca.its.rpi.edu - 23 Jul 1994 13:34}}

\vspace{1mm}

\fq{\cw{Thats wrong !
A 486 SX runs Doom with exactly the same speed like a 486 DX
(if you use the same VGA Card and Motherboard).}}{\cw{Grassl Wolfgang@papin.HRZ.Uni-Marburg.DE - 23 Jul 1994 14:24}}







